{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 批次下載 YouTube 清單影片，儲存到指定資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "from pytube import YouTube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定 YouTube 影片清單\n",
    "\n",
    "url = 'https://www.youtube.com/playlist?list=PLXO45tsB95cIuXEgV-mvYWRd_hVC43Akk'\n",
    "html = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#設定影片網址的正規表示式，即 /watch 後的網址內容\n",
    "\n",
    "res1 = re.findall(r'/watch[-A-Za-z0-9+&@#/%?=~_|!:,.;]+[-A-Za-z0-9+&@#/%=~_|]', html.text)  \n",
    "#print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "videourlList = []\n",
    "\n",
    "for temurl in res1:\n",
    "    if 'list=' and 'index=' in temurl:  #網址必須包含 list= 及 index= 才是正確的影片網址\n",
    "        if temurl not in videourlList:  #過濾重覆的網址，如果串列中不存在該網址才加入串列\n",
    "            videourlList.append(temurl)\n",
    "#print(videourlList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得目前資料夾路徑，將下載影片存於 download 資料夾，若此資料夾不存在便建立之\n",
    "\n",
    "filepath = os.getcwd()\n",
    "filepath = filepath+'\\\\download'\n",
    "#print(filepath)\n",
    "\n",
    "if not os.path.isdir(filepath):  #如果資料夾不存在就建立\n",
    "    os.mkdir(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始下載 YouTube 清單影片：\n",
      "1. #1 Why? (爬虫 scraping 基础教学/教程 Tutorial)\n",
      "2. #1.1 了解网页结构 (爬虫 scraping 基础教学/教程 Tutorial)\n",
      "3. #2.1 BeautifulSoup 解析网页: 基础 (爬虫 scraping 基础教学/教程 Tutorial)\n",
      "4. #2.2 BeautifulSoup 解析网页: CSS (爬虫 scraping 基础教学/教程 Tutorial)\n",
      "5. #2.3 BeautifulSoup 解析网页: 正则表达 (爬虫 scraping 基础教学/教程 Tutorial)\n",
      "6. #2.4 小练习: 爬百度百科 (爬虫 scraping 基础教学/教程 Tutorial)\n",
      "7. #3.1 Post 登录 Cookies Session 都用 Requests (爬虫 scraping 基础 Tutorial)\n",
      "8. #3.2 下载文件 (爬虫 scraping 基础)\n",
      "9. #3.3 小练习: 下载国家地理美图 (爬虫 scraping 基础)\n",
      "10. #4.1 加速爬虫: 多进程分布式 (爬虫 scraping 基础)\n",
      "11. #4.2 加速爬虫: 异步加载 Asyncio (爬虫 scraping 基础 Python)\n",
      "12. #5.1 让 Selenium 控制你的浏览器帮你玩爬虫 (爬虫 scraping 基础)\n",
      "13. #5.2 高效无忧的 Scrapy 爬虫库 (爬虫 scraping 基础)\n",
      "下載完成！\n"
     ]
    }
   ],
   "source": [
    "print('開始下載 YouTube 清單影片：')\n",
    "\n",
    "n = 1\n",
    "for video in videourlList:\n",
    "    yt = YouTube('https://www.youtube.com' + video)\n",
    "    print(str(n) + '. ' + yt.title)  #顯示標題\n",
    "    yt.streams.filter(subtype='mp4', res='360p', progressive=True).first().download(filepath)  #下載mp4,360p影片\n",
    "    n = n + 1\n",
    "print('下載完成！')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
